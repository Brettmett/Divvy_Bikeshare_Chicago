{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: \n",
    "    * 1. Unzip monthly tripdata \n",
    "    * 2. Creating a DataFrame with every trip in 2022\n",
    "    * 3. Cleaning Data/ changing datatypes\n",
    "    * 4. Push to sql database/store as csv on local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasource:\n",
    "https://divvy-tripdata.s3.amazonaws.com/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing needed Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Import libraries for SQL\n",
    "from sql_functions import get_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unzip monthly tripdata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants:\n",
    "path = \"data/\"\n",
    "schema = \"capstone_divvy_bikeshare\"\n",
    "engine = get_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['202206-divvy-tripdata.zip',\n",
       " '202208-divvy-tripdata.zip',\n",
       " '202205-divvy-tripdata.zip',\n",
       " '202203-divvy-tripdata.zip',\n",
       " '202210-divvy-tripdata.zip',\n",
       " '202211-divvy-tripdata.zip',\n",
       " '202201-divvy-tripdata.zip',\n",
       " '202202-divvy-tripdata.zip',\n",
       " '202212-divvy-tripdata.zip',\n",
       " '202209-divvy-tripdata.zip',\n",
       " '202204-divvy-tripdata.zip',\n",
       " '202207-divvy-tripdata.zip']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data folder for specific zip files from year 2022 and creating a list of filenames:\n",
    "list_tripfiles_2022 = []\n",
    "for file in os.listdir(path):\n",
    "    if file.startswith(\"2022\") and file.endswith(\"tripdata.zip\") == True:\n",
    "        list_tripfiles_2022.append(file)\n",
    "list_tripfiles_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C2F7DD78E82EC875</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-01-13 11:59:47</td>\n",
       "      <td>2022-01-13 12:02:44</td>\n",
       "      <td>Glenwood Ave &amp; Touhy Ave</td>\n",
       "      <td>525</td>\n",
       "      <td>Clark St &amp; Touhy Ave</td>\n",
       "      <td>RP-007</td>\n",
       "      <td>42.012800</td>\n",
       "      <td>-87.665906</td>\n",
       "      <td>42.012560</td>\n",
       "      <td>-87.674367</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A6CF8980A652D272</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-01-10 08:41:56</td>\n",
       "      <td>2022-01-10 08:46:17</td>\n",
       "      <td>Glenwood Ave &amp; Touhy Ave</td>\n",
       "      <td>525</td>\n",
       "      <td>Clark St &amp; Touhy Ave</td>\n",
       "      <td>RP-007</td>\n",
       "      <td>42.012763</td>\n",
       "      <td>-87.665967</td>\n",
       "      <td>42.012560</td>\n",
       "      <td>-87.674367</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BD0F91DFF741C66D</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-01-25 04:53:40</td>\n",
       "      <td>2022-01-25 04:58:01</td>\n",
       "      <td>Sheffield Ave &amp; Fullerton Ave</td>\n",
       "      <td>TA1306000016</td>\n",
       "      <td>Greenview Ave &amp; Fullerton Ave</td>\n",
       "      <td>TA1307000001</td>\n",
       "      <td>41.925602</td>\n",
       "      <td>-87.653708</td>\n",
       "      <td>41.925330</td>\n",
       "      <td>-87.665800</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBB80ED419105406</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-01-04 00:18:04</td>\n",
       "      <td>2022-01-04 00:33:00</td>\n",
       "      <td>Clark St &amp; Bryn Mawr Ave</td>\n",
       "      <td>KA1504000151</td>\n",
       "      <td>Paulina St &amp; Montrose Ave</td>\n",
       "      <td>TA1309000021</td>\n",
       "      <td>41.983593</td>\n",
       "      <td>-87.669154</td>\n",
       "      <td>41.961507</td>\n",
       "      <td>-87.671387</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DDC963BFDDA51EEA</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-01-20 01:31:10</td>\n",
       "      <td>2022-01-20 01:37:12</td>\n",
       "      <td>Michigan Ave &amp; Jackson Blvd</td>\n",
       "      <td>TA1309000002</td>\n",
       "      <td>State St &amp; Randolph St</td>\n",
       "      <td>TA1305000029</td>\n",
       "      <td>41.877850</td>\n",
       "      <td>-87.624080</td>\n",
       "      <td>41.884621</td>\n",
       "      <td>-87.627834</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type           started_at             ended_at  \\\n",
       "0  C2F7DD78E82EC875  electric_bike  2022-01-13 11:59:47  2022-01-13 12:02:44   \n",
       "1  A6CF8980A652D272  electric_bike  2022-01-10 08:41:56  2022-01-10 08:46:17   \n",
       "2  BD0F91DFF741C66D   classic_bike  2022-01-25 04:53:40  2022-01-25 04:58:01   \n",
       "3  CBB80ED419105406   classic_bike  2022-01-04 00:18:04  2022-01-04 00:33:00   \n",
       "4  DDC963BFDDA51EEA   classic_bike  2022-01-20 01:31:10  2022-01-20 01:37:12   \n",
       "\n",
       "              start_station_name start_station_id  \\\n",
       "0       Glenwood Ave & Touhy Ave              525   \n",
       "1       Glenwood Ave & Touhy Ave              525   \n",
       "2  Sheffield Ave & Fullerton Ave     TA1306000016   \n",
       "3       Clark St & Bryn Mawr Ave     KA1504000151   \n",
       "4    Michigan Ave & Jackson Blvd     TA1309000002   \n",
       "\n",
       "                end_station_name end_station_id  start_lat  start_lng  \\\n",
       "0           Clark St & Touhy Ave         RP-007  42.012800 -87.665906   \n",
       "1           Clark St & Touhy Ave         RP-007  42.012763 -87.665967   \n",
       "2  Greenview Ave & Fullerton Ave   TA1307000001  41.925602 -87.653708   \n",
       "3      Paulina St & Montrose Ave   TA1309000021  41.983593 -87.669154   \n",
       "4         State St & Randolph St   TA1305000029  41.877850 -87.624080   \n",
       "\n",
       "     end_lat    end_lng member_casual  \n",
       "0  42.012560 -87.674367        casual  \n",
       "1  42.012560 -87.674367        casual  \n",
       "2  41.925330 -87.665800        member  \n",
       "3  41.961507 -87.671387        casual  \n",
       "4  41.884621 -87.627834        member  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking a look at january:\n",
    "zf_jan22 = zipfile.ZipFile(\"data/202201-divvy-tripdata.zip\")\n",
    "df = pd.read_csv(zf_jan22.open(\"202201-divvy-tripdata.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function, to extract zipfiles, and store them in a dataframe:\n",
    "def zip_to_df(file):\n",
    "    # # exception: The zip file for september 2022 has a sightly differently called csv file:\n",
    "    if file == \"202209-divvy-tripdata.zip\":\n",
    "        zf = zipfile.ZipFile(path + \"202209-divvy-tripdata.zip\")\n",
    "        df = pd.read_csv(zf.open(\"202209-divvy-publictripdata\" + \".csv\"))\n",
    "    else:\n",
    "        zf = zipfile.ZipFile(path + file)\n",
    "        df = pd.read_csv(zf.open(file[:-4] + \".csv\"))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing zip_to_df function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5156990AC19CA285</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-09-01 08:36:22</td>\n",
       "      <td>2022-09-01 08:39:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California Ave &amp; Milwaukee Ave</td>\n",
       "      <td>13084</td>\n",
       "      <td>41.93</td>\n",
       "      <td>-87.69</td>\n",
       "      <td>41.922695</td>\n",
       "      <td>-87.697153</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E12D4A16BF51C274</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-09-01 17:11:29</td>\n",
       "      <td>2022-09-01 17:14:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.87</td>\n",
       "      <td>-87.62</td>\n",
       "      <td>41.870000</td>\n",
       "      <td>-87.620000</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A02B53CD7DB72DD7</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-09-01 17:15:50</td>\n",
       "      <td>2022-09-01 17:16:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.87</td>\n",
       "      <td>-87.62</td>\n",
       "      <td>41.870000</td>\n",
       "      <td>-87.620000</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C82E05FEE872DF11</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-09-01 09:00:28</td>\n",
       "      <td>2022-09-01 09:10:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.93</td>\n",
       "      <td>-87.69</td>\n",
       "      <td>41.940000</td>\n",
       "      <td>-87.670000</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4DEEB4550A266AE1</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-09-01 07:30:11</td>\n",
       "      <td>2022-09-01 07:32:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.92</td>\n",
       "      <td>-87.73</td>\n",
       "      <td>41.920000</td>\n",
       "      <td>-87.730000</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type           started_at             ended_at  \\\n",
       "0  5156990AC19CA285  electric_bike  2022-09-01 08:36:22  2022-09-01 08:39:05   \n",
       "1  E12D4A16BF51C274  electric_bike  2022-09-01 17:11:29  2022-09-01 17:14:45   \n",
       "2  A02B53CD7DB72DD7  electric_bike  2022-09-01 17:15:50  2022-09-01 17:16:12   \n",
       "3  C82E05FEE872DF11  electric_bike  2022-09-01 09:00:28  2022-09-01 09:10:32   \n",
       "4  4DEEB4550A266AE1  electric_bike  2022-09-01 07:30:11  2022-09-01 07:32:36   \n",
       "\n",
       "  start_station_name start_station_id                end_station_name  \\\n",
       "0                NaN              NaN  California Ave & Milwaukee Ave   \n",
       "1                NaN              NaN                             NaN   \n",
       "2                NaN              NaN                             NaN   \n",
       "3                NaN              NaN                             NaN   \n",
       "4                NaN              NaN                             NaN   \n",
       "\n",
       "  end_station_id  start_lat  start_lng    end_lat    end_lng member_casual  \n",
       "0          13084      41.93     -87.69  41.922695 -87.697153        casual  \n",
       "1            NaN      41.87     -87.62  41.870000 -87.620000        casual  \n",
       "2            NaN      41.87     -87.62  41.870000 -87.620000        casual  \n",
       "3            NaN      41.93     -87.69  41.940000 -87.670000        casual  \n",
       "4            NaN      41.92     -87.73  41.920000 -87.730000        casual  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_to_df(\"202209-divvy-tripdata.zip\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a DataFrame with every trip in 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets load all 12 zipfiles (one for every month of 2022) into a dataframe, and then concat them into one big df_22 dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting zipfile of every month into dataframes:\n",
    "for file in list_tripfiles_2022:\n",
    "    if \"202201\" in file:\n",
    "        df_01 = zip_to_df(file)\n",
    "    elif \"202202\" in file:\n",
    "        df_02 = zip_to_df(file)\n",
    "    elif \"202203\" in file:\n",
    "        df_03 = zip_to_df(file)\n",
    "    elif \"202204\" in file:\n",
    "        df_04 = zip_to_df(file)\n",
    "    elif \"202205\" in file:\n",
    "        df_05 = zip_to_df(file)\n",
    "    elif \"202206\" in file:\n",
    "        df_06 = zip_to_df(file)\n",
    "    elif \"202207\" in file:\n",
    "        df_07 = zip_to_df(file)\n",
    "    elif \"202208\" in file:\n",
    "        df_08 = zip_to_df(file)\n",
    "    elif \"202209\" in file:\n",
    "        df_09 = zip_to_df(file)\n",
    "    elif \"202210\" in file:\n",
    "        df_10 = zip_to_df(file)\n",
    "    elif \"202211\" in file:\n",
    "        df_11 = zip_to_df(file)\n",
    "    elif \"202212\" in file:\n",
    "        df_12 = zip_to_df(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinating monthly dataframes into a one year dataframe called df_22:\n",
    "df_22 = pd.concat([df_01, df_02, df_03, df_04, df_05, df_06, df_07, df_08, df_09, df_10, df_11, df_12], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning Data/ changing datatypes..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to clean the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df.rename(columns = {'started_at':'starttime', 'ended_at':'stoptime', 'start_station_name':'from_station_name', 'start_station_id':'from_station_id', 'end_station_name':'to_station_name', 'end_station_id':'to_station_id'}, inplace = True)\n",
    "    df['starttime'] = pd.to_datetime(df['starttime'])\n",
    "    df['stoptime'] = pd.to_datetime(df['stoptime'])\n",
    "    df['from_station_id'].fillna(0, inplace=True)\n",
    "    df['from_station_id'] = df['from_station_id'].astype('str')\n",
    "    df['from_station_id'] = df['from_station_id'].str.replace(\".0\", \"\")\n",
    "    df['from_station_id'] = df['from_station_id'].str.replace(\",\", \"\")\n",
    "    df['to_station_id'].fillna(0, inplace=True)\n",
    "    df['to_station_id'] = df['to_station_id'].astype('str')\n",
    "    df['to_station_id'] = df['to_station_id'].str.replace(\".0\", \"\")\n",
    "    df['to_station_id'] = df['to_station_id'].str.replace(\",\", \"\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.sort_values('starttime', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    # copy columns to a rearranged DataFrame\n",
    "    df_final = df[['ride_id', 'rideable_type', 'starttime', 'stoptime', 'from_station_id', 'from_station_name', 'to_station_id', 'to_station_name', 'start_lat', 'start_lng', 'end_lat', 'end_lng', 'member_casual']].copy()\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rb/9ddkw0p569d7d8xgjzc89f_c0000gn/T/ipykernel_13145/3306187110.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['from_station_id'] = df['from_station_id'].str.replace(\".0\", \"\")\n",
      "/var/folders/rb/9ddkw0p569d7d8xgjzc89f_c0000gn/T/ipykernel_13145/3306187110.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['to_station_id'] = df['to_station_id'].str.replace(\".0\", \"\")\n"
     ]
    }
   ],
   "source": [
    "df_22 = clean_df(df_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5667717 entries, 0 to 5667716\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   ride_id            object        \n",
      " 1   rideable_type      object        \n",
      " 2   starttime          datetime64[ns]\n",
      " 3   stoptime           datetime64[ns]\n",
      " 4   from_station_id    object        \n",
      " 5   from_station_name  object        \n",
      " 6   to_station_id      object        \n",
      " 7   to_station_name    object        \n",
      " 8   start_lat          float64       \n",
      " 9   start_lng          float64       \n",
      " 10  end_lat            float64       \n",
      " 11  end_lng            float64       \n",
      " 12  member_casual      object        \n",
      "dtypes: datetime64[ns](2), float64(4), object(7)\n",
      "memory usage: 562.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_22.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Push to sql database/store as csv on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trips_2022_test table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# #Push DataFrame to SQL Database:\n",
    "# table_name = 'trips_20xx'\n",
    "\n",
    "# df_22.to_sql(name=table_name, # Name of SQL table\n",
    "#                     con=engine, # Engine or connection\n",
    "#                     if_exists='replace', # Drop the table before inserting new values \n",
    "#                     schema=schema, # Use schema that was defined earlier\n",
    "#                     index=False, # Write DataFrame index as a column\n",
    "#                     chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "#                     method='multi') # Pass multiple values in a single INSERT clause\n",
    "# print(f\"The {table_name} table was imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_sql_geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
